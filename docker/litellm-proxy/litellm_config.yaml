# LiteLLM Proxy Configuration
# This file configures the unified API gateway for all AI models

model_list:
  # OpenAI Models
  - model_name: gpt-4-turbo-preview
    litellm_params:
      model: openai/gpt-4-turbo-preview
      api_key: os.environ/OPENAI_API_KEY
      
  - model_name: gpt-4
    litellm_params:
      model: openai/gpt-4
      api_key: os.environ/OPENAI_API_KEY
      
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY

  # Anthropic Models (Claude)
  - model_name: claude-3-opus-20240229
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      
  - model_name: claude-3-sonnet-20240229
    litellm_params:
      model: anthropic/claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      
  - model_name: claude-3-haiku-20240307
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY

  # Groq Models
  - model_name: groq-llama3-70b
    litellm_params:
      model: groq/llama3-70b-8192
      api_key: os.environ/GROQ_API_KEY
      
  - model_name: groq-mixtral
    litellm_params:
      model: groq/mixtral-8x7b-32768
      api_key: os.environ/GROQ_API_KEY

  # Google Vertex AI Models
  - model_name: gemini-pro
    litellm_params:
      model: vertex_ai/gemini-pro
      vertex_project: os.environ/GOOGLE_VERTEX_PROJECT_ID
      vertex_location: os.environ/GOOGLE_VERTEX_REGION

  # Ollama Models (Local)
  - model_name: ollama-codellama
    litellm_params:
      model: ollama/codellama
      api_base: os.environ/OLLAMA_API_BASE
      
  - model_name: ollama-llama3
    litellm_params:
      model: ollama/llama3
      api_base: os.environ/OLLAMA_API_BASE
      
  - model_name: ollama-mistral
    litellm_params:
      model: ollama/mistral
      api_base: os.environ/OLLAMA_API_BASE

# Router settings
router_settings:
  # Routing strategy: simple-shuffle, least-busy, usage-based-routing, latency-based-routing
  routing_strategy: simple-shuffle
  
  # Model fallbacks
  model_group_alias:
    gpt-4: ["gpt-4-turbo-preview", "claude-3-opus-20240229", "groq-llama3-70b"]
    gpt-3.5-turbo: ["gpt-3.5-turbo", "claude-3-haiku-20240307", "groq-mixtral"]
    
  # Retry configuration
  num_retries: 2
  request_timeout: 600
  fallbacks: [{"gpt-4-turbo-preview": ["claude-3-opus-20240229"]}, {"gpt-3.5-turbo": ["claude-3-haiku-20240307"]}]

# General settings
general_settings:
  # Master key for authentication (optional)
  master_key: os.environ/LITELLM_MASTER_KEY
  
  # Database for tracking usage (optional)
  database_url: os.environ/DATABASE_URL
  
  # Cache settings
  cache: true
  cache_params:
    type: "in-memory"
    ttl: 3600
    
  # Logging
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  
  # CORS
  allowed_origins: ["*"]