services:
  # Base image builder
  base:
    build:
      context: ./base
      dockerfile: Dockerfile
    image: llpm-base:latest
    container_name: llpm-base-builder
    command: /bin/true

  # Claude Code Assistant
  claude-code:
    build:
      context: ./claude-code
      dockerfile: Dockerfile
    depends_on:
      - base
    image: llpm-claude-code:latest
    container_name: claude-code
    env_file:
      - .env
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - CLAUDE_MODEL=${CLAUDE_MODEL:-claude-3-opus-20240229}
      - CLAUDE_CLI_OPTIONS=${CLAUDE_CLI_OPTIONS:-}
    volumes:
      - ../workspace:/claude-workspace
      - ${HOME}/.ssh:/root/.ssh:ro
      - ${HOME}/.gitconfig:/root/.gitconfig:ro
    working_dir: /claude-workspace
    stdin_open: true
    tty: true
    networks:
      - llpm-network
    healthcheck:
      test: ["CMD", "/usr/local/bin/healthcheck.sh"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  # OpenAI Codex Assistant
  openai-codex:
    build:
      context: ./openai-codex
      dockerfile: Dockerfile
    depends_on:
      - base
    image: llpm-openai-codex:latest
    container_name: openai-codex
    env_file:
      - .env
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4-turbo-preview}
      - OPENAI_ORG_ID=${OPENAI_ORG_ID}
      - OPENAI_CLI_OPTIONS=${OPENAI_CLI_OPTIONS:-}
    volumes:
      - ../workspace:/codex-workspace
      - ${HOME}/.ssh:/root/.ssh:ro
      - ${HOME}/.gitconfig:/root/.gitconfig:ro
    working_dir: /codex-workspace
    stdin_open: true
    tty: true
    networks:
      - llpm-network
    healthcheck:
      test: ["CMD", "/usr/local/bin/healthcheck.sh"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  # Aider Assistant
  aider:
    build:
      context: ./aider
      dockerfile: Dockerfile
    depends_on:
      - base
    image: llpm-aider:latest
    container_name: aider
    env_file:
      - .env
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - AIDER_MODEL=${AIDER_MODEL:-gpt-4-turbo-preview}
      - AIDER_AUTO_COMMITS=${AIDER_AUTO_COMMITS:-false}
      - AIDER_DARK_MODE=${AIDER_DARK_MODE:-true}
      - AIDER_CLI_OPTIONS=${AIDER_CLI_OPTIONS:-}
    volumes:
      - ../workspace:/aider-workspace
      - ${HOME}/.ssh:/root/.ssh:ro
      - ${HOME}/.gitconfig:/root/.gitconfig:ro
    working_dir: /aider-workspace
    stdin_open: true
    tty: true
    networks:
      - llpm-network
    healthcheck:
      test: ["CMD", "bash", "-c", "/usr/local/bin/healthcheck.sh && which aider"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  # OpenCode Assistant (Open-source models)
  opencode:
    build:
      context: ./opencode
      dockerfile: Dockerfile
    depends_on:
      - base
    image: llpm-opencode:latest
    container_name: opencode
    env_file:
      - .env
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://localhost:11434}
      - OPENCODE_MODEL=${OPENCODE_MODEL:-codellama}
      - LITELLM_MODEL=${LITELLM_MODEL}
      - OLLAMA_CLI_OPTIONS=${OLLAMA_CLI_OPTIONS:-}
      - LITELLM_CLI_OPTIONS=${LITELLM_CLI_OPTIONS:-}
    volumes:
      - ../workspace:/opencode-workspace
      - ${HOME}/.ssh:/root/.ssh:ro
      - ${HOME}/.gitconfig:/root/.gitconfig:ro
      - ollama-data:/root/.ollama
    working_dir: /opencode-workspace
    stdin_open: true
    tty: true
    networks:
      - llpm-network
    healthcheck:
      test: ["CMD", "/usr/local/bin/healthcheck.sh"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  # API Proxy Service (for secure API key management)
  api-proxy:
    build:
      context: ./api-proxy
      dockerfile: Dockerfile
    image: llpm-api-proxy:latest
    container_name: api-proxy
    env_file:
      - .env
    ports:
      - "8080:8080"
    networks:
      - llpm-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s

networks:
  llpm-network:
    driver: bridge
    name: llpm-network

volumes:
  ollama-data:
    driver: local